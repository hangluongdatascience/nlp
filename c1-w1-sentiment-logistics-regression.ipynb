{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hnglng/c1-w1-sentiment-logistics-regression?scriptVersionId=175221475\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"df578675","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-02T07:28:54.348623Z","iopub.status.busy":"2024-05-02T07:28:54.348164Z","iopub.status.idle":"2024-05-02T07:28:55.270617Z","shell.execute_reply":"2024-05-02T07:28:55.269417Z"},"papermill":{"duration":0.93782,"end_time":"2024-05-02T07:28:55.273776","exception":false,"start_time":"2024-05-02T07:28:54.335956","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"2cffdf58","metadata":{"papermill":{"duration":0.008006,"end_time":"2024-05-02T07:28:55.290542","exception":false,"start_time":"2024-05-02T07:28:55.282536","status":"completed"},"tags":[]},"source":["# **NLP SPECIALIZATION**\n","\n","\n","# Course 1: Classification and Vector space\n","\n","**Week 1: Sentiment Analysis with Logistic regression**\n","\n","Week 2: Sentiment Analysis with Naive Bayes's\n","\n","Week 3: Vector Space Models\n","\n","Week 4: Machine Translation and Document Search\n"]},{"cell_type":"markdown","id":"370f8772","metadata":{"papermill":{"duration":0.007732,"end_time":"2024-05-02T07:28:55.306054","exception":false,"start_time":"2024-05-02T07:28:55.298322","status":"completed"},"tags":[]},"source":["# Sentiment Analysis with Logistic regression"]},{"cell_type":"markdown","id":"36e5e098","metadata":{"papermill":{"duration":0.007316,"end_time":"2024-05-02T07:28:55.321529","exception":false,"start_time":"2024-05-02T07:28:55.314213","status":"completed"},"tags":[]},"source":["# 1. Data Preparation"]},{"cell_type":"code","execution_count":2,"id":"a104c6fa","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:28:55.339829Z","iopub.status.busy":"2024-05-02T07:28:55.339285Z","iopub.status.idle":"2024-05-02T07:28:57.693194Z","shell.execute_reply":"2024-05-02T07:28:57.692141Z"},"papermill":{"duration":2.366245,"end_time":"2024-05-02T07:28:57.696008","exception":false,"start_time":"2024-05-02T07:28:55.329763","status":"completed"},"tags":[]},"outputs":[],"source":["# import library\n","import nltk\n","from os import getcwd"]},{"cell_type":"code","execution_count":3,"id":"c3fb6e8f","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:28:57.71536Z","iopub.status.busy":"2024-05-02T07:28:57.714687Z","iopub.status.idle":"2024-05-02T07:28:57.720435Z","shell.execute_reply":"2024-05-02T07:28:57.719008Z"},"papermill":{"duration":0.018552,"end_time":"2024-05-02T07:28:57.723452","exception":false,"start_time":"2024-05-02T07:28:57.7049","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from nltk.corpus import twitter_samples "]},{"cell_type":"code","execution_count":4,"id":"ad28edf0","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:28:57.745187Z","iopub.status.busy":"2024-05-02T07:28:57.744281Z","iopub.status.idle":"2024-05-02T07:28:57.759302Z","shell.execute_reply":"2024-05-02T07:28:57.758067Z"},"papermill":{"duration":0.027515,"end_time":"2024-05-02T07:28:57.761772","exception":false,"start_time":"2024-05-02T07:28:57.734257","status":"completed"},"tags":[]},"outputs":[],"source":["# create some helper function because I can't get it from deeplearning.ai\n","import re\n","import string\n","import numpy as np\n","\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import TweetTokenizer\n","\n","\n","def process_tweet(tweet):\n","    \"\"\"Process tweet function.\n","    Input:\n","        tweet: a string containing a tweet\n","    Output:\n","        tweets_clean: a list of words containing the processed tweet\n","    \"\"\"\n","    stemmer = PorterStemmer()\n","    stopwords_english = stopwords.words('english')\n","    # remove stock market tickers like $GE\n","    tweet = re.sub(r'\\$\\w*', '', tweet)\n","    # remove old style retweet text \"RT\"\n","    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n","    # remove hyperlinks\n","    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n","    # remove hashtags\n","    # only removing the hash # sign from the word\n","    tweet = re.sub(r'#', '', tweet)\n","    # tokenize tweets\n","    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n","                               reduce_len=True)\n","    tweet_tokens = tokenizer.tokenize(tweet)\n","\n","    tweets_clean = []\n","    for word in tweet_tokens:\n","        if (word not in stopwords_english and  # remove stopwords\n","                word not in string.punctuation):  # remove punctuation\n","            # tweets_clean.append(word)\n","            stem_word = stemmer.stem(word)  # stemming word\n","            tweets_clean.append(stem_word)\n","\n","    return tweets_clean\n","\n","\n","def build_freqs(tweets, ys):\n","    \"\"\"Build frequencies.\n","    Input:\n","        tweets: a list of tweets\n","        ys: an m x 1 array with the sentiment label of each tweet\n","            (either 0 or 1)\n","    Output:\n","        freqs: a dictionary mapping each (word, sentiment) pair to its\n","        frequency\n","    \"\"\"\n","    # Convert np array to list since zip needs an iterable.\n","    # The squeeze is necessary or the list ends up with one element.\n","    # Also note that this is just a NOP if ys is already a list.\n","    yslist = np.squeeze(ys).tolist()\n","\n","    # Start with an empty dictionary and populate it by looping over all tweets\n","    # and over all processed words in each tweet.\n","    freqs = {}\n","    for y, tweet in zip(yslist, tweets):\n","        for word in process_tweet(tweet):\n","            pair = (word, y)\n","            if pair in freqs:\n","                freqs[pair] += 1\n","            else:\n","                freqs[pair] = 1\n","\n","    return freqs"]},{"cell_type":"code","execution_count":5,"id":"c8e7aa57","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:28:57.78406Z","iopub.status.busy":"2024-05-02T07:28:57.783609Z","iopub.status.idle":"2024-05-02T07:28:58.642903Z","shell.execute_reply":"2024-05-02T07:28:58.641535Z"},"papermill":{"duration":0.875358,"end_time":"2024-05-02T07:28:58.645563","exception":false,"start_time":"2024-05-02T07:28:57.770205","status":"completed"},"tags":[]},"outputs":[],"source":["# PREPARE DATA\n","# select the set of positive and negative tweets\n","all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n","all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n"]},{"cell_type":"code","execution_count":6,"id":"dccd53b3","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:28:58.665449Z","iopub.status.busy":"2024-05-02T07:28:58.665036Z","iopub.status.idle":"2024-05-02T07:28:58.67139Z","shell.execute_reply":"2024-05-02T07:28:58.669885Z"},"papermill":{"duration":0.020312,"end_time":"2024-05-02T07:28:58.674424","exception":false,"start_time":"2024-05-02T07:28:58.654112","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["5000 5000\n"]}],"source":["print(len(all_negative_tweets),len(all_positive_tweets))"]},{"cell_type":"code","execution_count":7,"id":"fd8b7f7d","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:28:58.694755Z","iopub.status.busy":"2024-05-02T07:28:58.694326Z","iopub.status.idle":"2024-05-02T07:28:58.701985Z","shell.execute_reply":"2024-05-02T07:28:58.69992Z"},"papermill":{"duration":0.023017,"end_time":"2024-05-02T07:28:58.705126","exception":false,"start_time":"2024-05-02T07:28:58.682109","status":"completed"},"tags":[]},"outputs":[],"source":["# split the data into two pieces, one for training and one for testing (validation set)  (80-20)\n","test_pos = all_positive_tweets[4000:]\n","train_pos = all_positive_tweets[:4000]\n","test_neg = all_negative_tweets[4000:]\n","train_neg = all_negative_tweets[:4000]\n","\n","train_x = train_pos + train_neg \n","test_x = test_pos + test_neg"]},{"cell_type":"code","execution_count":8,"id":"cc6aec08","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:28:58.72416Z","iopub.status.busy":"2024-05-02T07:28:58.723709Z","iopub.status.idle":"2024-05-02T07:28:58.731351Z","shell.execute_reply":"2024-05-02T07:28:58.729741Z"},"papermill":{"duration":0.019884,"end_time":"2024-05-02T07:28:58.734009","exception":false,"start_time":"2024-05-02T07:28:58.714125","status":"completed"},"tags":[]},"outputs":[],"source":["# combine positive and negative labels\n","train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n","test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"]},{"cell_type":"code","execution_count":9,"id":"68251c6c","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:28:58.751792Z","iopub.status.busy":"2024-05-02T07:28:58.751329Z","iopub.status.idle":"2024-05-02T07:28:58.758423Z","shell.execute_reply":"2024-05-02T07:28:58.756728Z"},"papermill":{"duration":0.018817,"end_time":"2024-05-02T07:28:58.760993","exception":false,"start_time":"2024-05-02T07:28:58.742176","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["train_y.shape = (8000, 1)\n","test_y.shape = (2000, 1)\n"]}],"source":["# Print the shape train and test sets\n","print(\"train_y.shape = \" + str(train_y.shape))\n","print(\"test_y.shape = \" + str(test_y.shape))"]},{"cell_type":"code","execution_count":10,"id":"d3e776ea","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:28:58.780273Z","iopub.status.busy":"2024-05-02T07:28:58.779866Z","iopub.status.idle":"2024-05-02T07:29:02.562257Z","shell.execute_reply":"2024-05-02T07:29:02.560693Z"},"papermill":{"duration":3.795936,"end_time":"2024-05-02T07:29:02.565398","exception":false,"start_time":"2024-05-02T07:28:58.769462","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["type(freqs) = <class 'dict'>\n","len(freqs) = 11346\n"]}],"source":["# create frequency dictionary\n","freqs = build_freqs(train_x, train_y)\n","\n","# check the output\n","print(\"type(freqs) = \" + str(type(freqs)))\n","print(\"len(freqs) = \" + str(len(freqs.keys())))"]},{"cell_type":"code","execution_count":11,"id":"df6abb06","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.583806Z","iopub.status.busy":"2024-05-02T07:29:02.583345Z","iopub.status.idle":"2024-05-02T07:29:02.591094Z","shell.execute_reply":"2024-05-02T07:29:02.589867Z"},"papermill":{"duration":0.020049,"end_time":"2024-05-02T07:29:02.593993","exception":false,"start_time":"2024-05-02T07:29:02.573944","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["This is an example of a positive tweet: \n"," #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n","\n","This is an example of the processed version of the tweet: \n"," ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"]}],"source":["# test the function below\n","print('This is an example of a positive tweet: \\n', train_x[0])\n","print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"]},{"cell_type":"markdown","id":"0af65f85","metadata":{"papermill":{"duration":0.008595,"end_time":"2024-05-02T07:29:02.61204","exception":false,"start_time":"2024-05-02T07:29:02.603445","status":"completed"},"tags":[]},"source":["# 2. Logistics Regression"]},{"cell_type":"code","execution_count":12,"id":"c57968f0","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.631082Z","iopub.status.busy":"2024-05-02T07:29:02.630661Z","iopub.status.idle":"2024-05-02T07:29:02.637353Z","shell.execute_reply":"2024-05-02T07:29:02.635832Z"},"papermill":{"duration":0.019101,"end_time":"2024-05-02T07:29:02.639617","exception":false,"start_time":"2024-05-02T07:29:02.620516","status":"completed"},"tags":[]},"outputs":[],"source":["# SIGMOID FUNCTION IMPLEMENT (1/(1+exp)^−z)\n","def sigmoid(z): \n","    '''\n","    Input:\n","        z: is the input (can be a scalar or an array)\n","    Output:\n","        h: the sigmoid of z\n","    '''\n","    \n","    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n","    # calculate the sigmoid of z\n","    h = 1 / (1 + np.exp(-z))\n","    ### END CODE HERE ###\n","    \n","    return h"]},{"cell_type":"code","execution_count":13,"id":"df15dcc6","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.658948Z","iopub.status.busy":"2024-05-02T07:29:02.657873Z","iopub.status.idle":"2024-05-02T07:29:02.665127Z","shell.execute_reply":"2024-05-02T07:29:02.66417Z"},"papermill":{"duration":0.019253,"end_time":"2024-05-02T07:29:02.667544","exception":false,"start_time":"2024-05-02T07:29:02.648291","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["SUCCESS!\n","CORRECT!\n"]}],"source":["# Testing your function \n","if (sigmoid(0) == 0.5):\n","    print('SUCCESS!')\n","else:\n","    print('Oops!')\n","\n","if (sigmoid(4.92) == 0.9927537604041685):\n","    print('CORRECT!')\n","else:\n","    print('Oops again!')"]},{"cell_type":"code","execution_count":14,"id":"8e707925","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.692075Z","iopub.status.busy":"2024-05-02T07:29:02.690963Z","iopub.status.idle":"2024-05-02T07:29:02.700364Z","shell.execute_reply":"2024-05-02T07:29:02.699062Z"},"papermill":{"duration":0.023159,"end_time":"2024-05-02T07:29:02.702739","exception":false,"start_time":"2024-05-02T07:29:02.67958","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["9.210340371976182"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Logistics regression and sigmoid : z=θ0x0+θ1x1+θ2x2+...θNxN\n","# verify that when the model predicts close to 1, but the actual label is 0, the loss is a large positive value\n","-1 * (1 - 0) * np.log(1 - 0.9999) # loss is about 9.2\n","# verify that when the model predicts close to 0 but the actual label is 1, the loss is a large positive value\n","-1 * np.log(0.0001) # loss is about 9.2"]},{"cell_type":"code","execution_count":15,"id":"8b832daa","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.721042Z","iopub.status.busy":"2024-05-02T07:29:02.720578Z","iopub.status.idle":"2024-05-02T07:29:02.731085Z","shell.execute_reply":"2024-05-02T07:29:02.729535Z"},"papermill":{"duration":0.022791,"end_time":"2024-05-02T07:29:02.733756","exception":false,"start_time":"2024-05-02T07:29:02.710965","status":"completed"},"tags":[]},"outputs":[],"source":["#  Implement gradient descent function\n","def gradientDescent(x, y, theta, alpha, num_iters):\n","    '''\n","    Input:\n","        x: matrix of features which is (m,n+1)\n","        y: corresponding labels of the input matrix x, dimensions (m,1)\n","        theta: weight vector of dimension (n+1,1)\n","        alpha: learning rate\n","        num_iters: number of iterations you want to train your model for\n","    Output:\n","        J: the final cost\n","        theta: your final weight vector\n","    Hint: you might want to print the cost to make sure that it is going down.\n","    '''\n","    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n","    # get 'm', the number of rows in matrix x\n","    m = x.shape[0]\n","    \n","    for i in range(0, num_iters):\n","        \n","        # get z, the dot product of x and theta\n","        z = np.dot(x,theta)\n","        \n","        # get the sigmoid of h\n","        h = sigmoid(z)\n","        \n","        # calculate the cost function\n","        # note that we can use also np.array.transpose() instead of np.array.T\n","        # np.array.T just makes code a little more readable :)\n","        J = -1./m * (np.dot(y.T, np.log(h)) + np.dot((1-y).T,np.log(1-h)))                                                    \n","\n","        # update the weights theta\n","        theta = theta - (alpha/m) * np.dot(x.T,(h-y))\n","        \n","    ### END CODE HERE ###\n","    J = float(J)\n","    return J, theta"]},{"cell_type":"code","execution_count":16,"id":"0673755f","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.752456Z","iopub.status.busy":"2024-05-02T07:29:02.752021Z","iopub.status.idle":"2024-05-02T07:29:02.779492Z","shell.execute_reply":"2024-05-02T07:29:02.777938Z"},"papermill":{"duration":0.040169,"end_time":"2024-05-02T07:29:02.782307","exception":false,"start_time":"2024-05-02T07:29:02.742138","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The cost after training is 0.67094970.\n","The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_18/505913467.py:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  J = float(J)\n"]}],"source":["# Check the function\n","# Construct a synthetic test case using numpy PRNG functions\n","np.random.seed(1)\n","# X input is 10 x 3 with ones for the bias terms\n","tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n","# Y Labels are 10 x 1\n","tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n","\n","# Apply gradient descent\n","tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n","print(f\"The cost after training is {tmp_J:.8f}.\")\n","print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"]},{"cell_type":"code","execution_count":17,"id":"ab2399be","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.803421Z","iopub.status.busy":"2024-05-02T07:29:02.802995Z","iopub.status.idle":"2024-05-02T07:29:02.810159Z","shell.execute_reply":"2024-05-02T07:29:02.808814Z"},"papermill":{"duration":0.021015,"end_time":"2024-05-02T07:29:02.813079","exception":false,"start_time":"2024-05-02T07:29:02.792064","status":"completed"},"tags":[]},"outputs":[],"source":["# Implement the extract_features function.\n","def extract_features(tweet, freqs):\n","    '''\n","    Input: \n","        tweet: a list of words for one tweet\n","        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n","    Output: \n","        x: a feature vector of dimension (1,3)\n","    '''\n","    # process_tweet tokenizes, stems, and removes stopwords\n","    word_l = process_tweet(tweet)\n","    \n","    # 3 elements in the form of a 1 x 3 vector\n","    x = np.zeros((1, 3)) \n","    \n","    #bias term is set to 1\n","    x[0,0] = 1 \n","    \n","    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n","    \n","    # loop through each word in the list of words\n","    for word in word_l:\n","        \n","        # increment the word count for the positive label 1\n","        x[0,1] += freqs.get((word, 1.0),0)\n","        \n","        # increment the word count for the negative label 0\n","        x[0,2] += freqs.get((word, 0.0),0)\n","        \n","    ### END CODE HERE ###\n","    assert(x.shape == (1, 3))\n","    return x"]},{"cell_type":"code","execution_count":18,"id":"cfab25b2","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.83285Z","iopub.status.busy":"2024-05-02T07:29:02.8324Z","iopub.status.idle":"2024-05-02T07:29:02.839975Z","shell.execute_reply":"2024-05-02T07:29:02.838923Z"},"papermill":{"duration":0.020617,"end_time":"2024-05-02T07:29:02.842312","exception":false,"start_time":"2024-05-02T07:29:02.821695","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.00e+00 3.02e+03 6.10e+01]]\n"]}],"source":["# Check your function\n","\n","# test 1\n","# test on training data\n","tmp1 = extract_features(train_x[0], freqs)\n","print(tmp1)"]},{"cell_type":"code","execution_count":19,"id":"d9eb8517","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.862143Z","iopub.status.busy":"2024-05-02T07:29:02.861761Z","iopub.status.idle":"2024-05-02T07:29:02.869051Z","shell.execute_reply":"2024-05-02T07:29:02.867739Z"},"papermill":{"duration":0.019337,"end_time":"2024-05-02T07:29:02.871248","exception":false,"start_time":"2024-05-02T07:29:02.851911","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1. 0. 0.]]\n"]}],"source":["# test 2:\n","# check for when the words are not in the freqs dictionary\n","tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n","print(tmp2)"]},{"cell_type":"markdown","id":"f45f0656","metadata":{"papermill":{"duration":0.008094,"end_time":"2024-05-02T07:29:02.887623","exception":false,"start_time":"2024-05-02T07:29:02.879529","status":"completed"},"tags":[]},"source":["**Trainning Model**"]},{"cell_type":"code","execution_count":20,"id":"1a43dc51","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:02.906593Z","iopub.status.busy":"2024-05-02T07:29:02.90622Z","iopub.status.idle":"2024-05-02T07:29:07.650857Z","shell.execute_reply":"2024-05-02T07:29:07.649204Z"},"papermill":{"duration":4.762395,"end_time":"2024-05-02T07:29:07.658756","exception":false,"start_time":"2024-05-02T07:29:02.896361","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The cost after training is 0.24216529.\n","The resulting vector of weights is [7e-08, 0.0005239, -0.00055517]\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_18/505913467.py:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  J = float(J)\n"]}],"source":["# collect the features 'x' and stack them into a matrix 'X'\n","X = np.zeros((len(train_x), 3))\n","for i in range(len(train_x)):\n","    X[i, :]= extract_features(train_x[i], freqs)\n","\n","# training labels corresponding to X\n","Y = train_y\n","\n","# Apply gradient descent\n","J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n","print(f\"The cost after training is {J:.8f}.\")\n","print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"]},{"cell_type":"code","execution_count":21,"id":"c499ee74","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:07.693806Z","iopub.status.busy":"2024-05-02T07:29:07.693247Z","iopub.status.idle":"2024-05-02T07:29:07.700964Z","shell.execute_reply":"2024-05-02T07:29:07.699648Z"},"papermill":{"duration":0.030253,"end_time":"2024-05-02T07:29:07.703975","exception":false,"start_time":"2024-05-02T07:29:07.673722","status":"completed"},"tags":[]},"outputs":[],"source":["# Test logistic regression in the dataset \n","def predict_tweet(tweet, freqs, theta):\n","    '''\n","    Input: \n","        tweet: a string\n","        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n","        theta: (3,1) vector of weights\n","    Output: \n","        y_pred: the probability of a tweet being positive or negative\n","    '''\n","    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n","    \n","    # extract the features of the tweet and store it into x\n","    x = extract_features(tweet,freqs)\n","    \n","    # make the prediction using x and theta\n","    y_pred = sigmoid(np.dot(x,theta))\n","    \n","    ### END CODE HERE ###\n","    \n","    return y_pred"]},{"cell_type":"code","execution_count":22,"id":"d7b6e01d","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:07.738441Z","iopub.status.busy":"2024-05-02T07:29:07.737871Z","iopub.status.idle":"2024-05-02T07:29:07.752845Z","shell.execute_reply":"2024-05-02T07:29:07.751596Z"},"papermill":{"duration":0.035391,"end_time":"2024-05-02T07:29:07.755972","exception":false,"start_time":"2024-05-02T07:29:07.720581","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["I am happy -> 0.518580\n","I am bad -> 0.494339\n","this movie should have been great. -> 0.515331\n","great -> 0.515464\n","great great -> 0.530898\n","great great great -> 0.546273\n","great great great great -> 0.561561\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_18/2209103747.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))\n"]}],"source":["# Run this cell to test your function\n","for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n","    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))"]},{"cell_type":"code","execution_count":23,"id":"47f26201","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:07.781937Z","iopub.status.busy":"2024-05-02T07:29:07.781544Z","iopub.status.idle":"2024-05-02T07:29:07.78942Z","shell.execute_reply":"2024-05-02T07:29:07.788456Z"},"papermill":{"duration":0.021616,"end_time":"2024-05-02T07:29:07.791749","exception":false,"start_time":"2024-05-02T07:29:07.770133","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([[0.49986711]])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Feel free to check the sentiment of your own tweet below\n","my_tweet = 'this movie about genocide'\n","predict_tweet(my_tweet, freqs, theta)"]},{"cell_type":"code","execution_count":24,"id":"f2aa805b","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:07.814166Z","iopub.status.busy":"2024-05-02T07:29:07.813487Z","iopub.status.idle":"2024-05-02T07:29:07.819975Z","shell.execute_reply":"2024-05-02T07:29:07.818982Z"},"papermill":{"duration":0.020841,"end_time":"2024-05-02T07:29:07.822859","exception":false,"start_time":"2024-05-02T07:29:07.802018","status":"completed"},"tags":[]},"outputs":[],"source":["# Check performance using the test set\n","def test_logistic_regression(test_x, test_y, freqs, theta):\n","    \"\"\"\n","    Input: \n","        test_x: a list of tweets\n","        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n","        freqs: a dictionary with the frequency of each pair (or tuple)\n","        theta: weight vector of dimension (3, 1)\n","    Output: \n","        accuracy: (# of tweets classified correctly) / (total # of tweets)\n","    \"\"\"\n","    \n","    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n","    \n","    # the list for storing predictions\n","    y_hat = []\n","    \n","    for tweet in test_x:\n","        # get the label prediction for the tweet\n","        y_pred = predict_tweet(tweet, freqs, theta)\n","        \n","        if y_pred > 0.5:\n","            # append 1.0 to the list\n","            y_hat.append(1)\n","        else:\n","            # append 0 to the list\n","            y_hat.append(0)\n","\n","    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n","    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n","    \n","    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n","    ### END CODE HERE ###\n","    \n","    return accuracy"]},{"cell_type":"code","execution_count":25,"id":"01b7ea0c","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:07.843376Z","iopub.status.busy":"2024-05-02T07:29:07.842701Z","iopub.status.idle":"2024-05-02T07:29:08.913705Z","shell.execute_reply":"2024-05-02T07:29:08.912377Z"},"papermill":{"duration":1.083993,"end_time":"2024-05-02T07:29:08.916197","exception":false,"start_time":"2024-05-02T07:29:07.832204","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic regression model's accuracy = 0.9950\n"]}],"source":["tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n","print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"]},{"cell_type":"markdown","id":"61fe56f9","metadata":{"papermill":{"duration":0.008661,"end_time":"2024-05-02T07:29:08.934182","exception":false,"start_time":"2024-05-02T07:29:08.925521","status":"completed"},"tags":[]},"source":["**Error Analysis**\n"]},{"cell_type":"code","execution_count":26,"id":"1a66a4e8","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:08.955109Z","iopub.status.busy":"2024-05-02T07:29:08.954412Z","iopub.status.idle":"2024-05-02T07:29:10.052752Z","shell.execute_reply":"2024-05-02T07:29:10.05183Z"},"papermill":{"duration":1.111225,"end_time":"2024-05-02T07:29:10.05512","exception":false,"start_time":"2024-05-02T07:29:08.943895","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Label Predicted Tweet\n","THE TWEET IS: @jaredNOTsubway @iluvmariah @Bravotv Then that truly is a LATERAL move! Now, we all know the Queen Bee is UPWARD BOUND : ) #MovingOnUp\n","THE PROCESSED TWEET IS: ['truli', 'later', 'move', 'know', 'queen', 'bee', 'upward', 'bound', 'movingonup']\n","1\t0.49996890\tb'truli later move know queen bee upward bound movingonup'\n","THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n","THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n","1\t0.48622857\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n","THE TWEET IS: I'm playing Brain Dots : ) #BrainDots\n","http://t.co/UGQzOx0huu\n","THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n","1\t0.48370665\tb\"i'm play brain dot braindot\"\n","THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n","THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n","1\t0.48370665\tb\"i'm play brain dot braindot\"\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_18/289099189.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))\n"]},{"name":"stdout","output_type":"stream","text":["THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n","THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n","1\t0.48370665\tb\"i'm play brain dot braindot\"\n","THE TWEET IS: off to the park to get some sunlight : )\n","THE PROCESSED TWEET IS: ['park', 'get', 'sunlight']\n","1\t0.49578765\tb'park get sunlight'\n","THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n","THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n","1\t0.48199810\tb'uff itna miss karhi thi ap :p'\n","THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n","THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n","0\t0.50020353\tb'u prob fun david'\n","THE TWEET IS: pats jay : (\n","THE PROCESSED TWEET IS: ['pat', 'jay']\n","0\t0.50039294\tb'pat jay'\n","THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n","THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n","0\t0.50000002\tb'belov grandmoth'\n"]}],"source":["# Some error analysis done for you\n","print('Label Predicted Tweet')\n","for x,y in zip(test_x,test_y):\n","    y_hat = predict_tweet(x, freqs, theta)\n","\n","    if np.abs(y - (y_hat > 0.5)) > 0:\n","        print('THE TWEET IS:', x)\n","        print('THE PROCESSED TWEET IS:', process_tweet(x))\n","        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"]},{"cell_type":"code","execution_count":27,"id":"901f75d2","metadata":{"execution":{"iopub.execute_input":"2024-05-02T07:29:10.077437Z","iopub.status.busy":"2024-05-02T07:29:10.077014Z","iopub.status.idle":"2024-05-02T07:29:10.088023Z","shell.execute_reply":"2024-05-02T07:29:10.087049Z"},"papermill":{"duration":0.025467,"end_time":"2024-05-02T07:29:10.090402","exception":false,"start_time":"2024-05-02T07:29:10.064935","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n","[[0.48139087]]\n","Negative sentiment\n"]}],"source":["# Test on my own dataa\n","# Feel free to change the tweet below\n","my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n","print(process_tweet(my_tweet))\n","y_hat = predict_tweet(my_tweet, freqs, theta)\n","print(y_hat)\n","if y_hat > 0.5:\n","    print('Positive sentiment')\n","else: \n","    print('Negative sentiment')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":19.470481,"end_time":"2024-05-02T07:29:10.824698","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-02T07:28:51.354217","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}